name: Big Data Pipeline CI/CD

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:

  ##########################################################################
  # 1️⃣ UNIT TESTS  (runs on host, no Docker needed)
  ##########################################################################
  unit-tests:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-mock

      - name: Run unit tests
        run: pytest -m unit -v


  ##########################################################################
  # 2️⃣ BUILD & START ALL SERVICES
  ##########################################################################
  start-services:
    runs-on: ubuntu-latest
    needs: unit-tests          # only run if unit tests passed

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Install Docker Compose
        uses: docker/setup-compose-action@v1

      - name: Verify Docker Compose installation
        run: | 
          which docker-compose || echo "docker-compose not found"
          docker compose version 
          docker version

      - name: Start docker compose services
        run: |
          docker compose up -d --build
          sleep 40               # wait for ES, Kafka, MySQL, Spark, etc.

      - name: Show running containers
        run: docker ps -a


  ##########################################################################
  # 3️⃣ INTEGRATION TESTS
  ##########################################################################
  integration-tests:
    runs-on: ubuntu-latest
    needs: start-services

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Install pytest
        run: |
          pip install pytest pytest-mock elasticsearch mysql-connector-python

      - name: Run integration tests inside Docker network
        run: |
          docker run --rm -i \
            --network search-and-big-data-processing_default \
            -v $PWD:/app \
            -w /app \
            python:3.11 \
            pytest -m integration -v


  ##########################################################################
  # 4️⃣ SYSTEM TESTS (Full ETL + Search Pipeline)
  ##########################################################################
  system-tests:
    runs-on: ubuntu-latest
    needs: integration-tests

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Install pytest
        run: |
          pip install pytest pytest-mock elasticsearch mysql-connector-python

      - name: Run system tests inside Docker network
        run: |
          docker run --rm -i \
            --network search-and-big-data-processing_default \
            -v $PWD:/app \
            -w /app \
            python:3.11 \
            pytest -m system -v


  ##########################################################################
  # 5️⃣ DEPLOY (Optional: deploy FastAPI, Kafka, Streamlit, etc. to Linode)
  ##########################################################################
  deploy:
    runs-on: ubuntu-latest
    needs: system-tests

    if: github.ref == 'refs/heads/main'

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up SSH
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.LINODE_SSH_KEY }}" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa

      - name: Deploy to Linode
        run: |
          ssh -o StrictHostKeyChecking=no ${{ secrets.LINODE_USER }}@${{ secrets.LINODE_IP }} "
            cd /your/project/path &&
            docker-compose pull &&
            docker-compose up -d --build
          "
