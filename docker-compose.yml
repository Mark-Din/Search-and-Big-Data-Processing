# # ---------------
# # search_system
# # ---------------
services:
  elasticsearch:
    build:
      context: ./search_system
      dockerfile: Dockerfile
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=true  # Keep security enabled
      # - xpack.security.http.ssl.enabled=true
      # - xpack.security.http.ssl.keystore.path=certs/http.p12
      # - xpack.security.http.ssl.truststore.path=certs/http.p12
      - ELASTIC_PASSWORD=gAcstb8v-lFCVzCBC__a  # Set password manually
    volumes:
      - ./search_system/es_certs/http_ca.crt:/usr/share/elasticsearch/config/certs/http_ca.crt  # Mount certificates 
    profiles:
      - search    
    ports:
      - "9200:9200"
      - "9300:9300"
    networks:
      - bigdata-net

  fastapi_search_service:
    build:
      context: ./search_system/FastAPI_service
      dockerfile: Dockerfile
    container_name: fastapi_search_service
    volumes:
      - ./search_system/es_certs:/usr/certs
      - ./search_system/FastAPI_service/code:/app  # Persistent data storage for FastAPI
    environment:
      - ES_USERNAME=elastic
      - ES_PASSWORD=gAcstb8v-lFCVzCBC__a  # Use the manually set password
      - ES_HOST=http://elasticsearch:9200
      - ES_CA_CERT=/usr/certs/http_ca.crt  # Optional, if you're using SSL
    networks:
      - bigdata-net
    profiles:
      - search    
    depends_on:
      - elasticsearch
    ports:
      - "3002:3002"  # Expose FastAPI on port 8000

  # mysql_db:
  #   image: mysql:5.7
  #   container_name: mysql_db_container
  #   environment:
  #     MYSQL_ROOT_PASSWORD: "!QAZ2wsx"
  #     MYSQL_ROOT_HOST: "%"
  #     MYSQL_DATABASE: nexva
  #     MYSQL_CHARSET: utf8
  #     MYSQL_COLLATION: utf8_general_ci
  #   volumes:
  #     - ./sql/my.cnf:/etc/mysql/conf.d/my.cnf
  #     - my-datavolume:/var/lib/mysql
  #   ports:
  #     - "3307:3306"  # Expose MySQL on port 3306
  #   profiles:
  #     - search    
  #   networks:
  #     - bigdata-net

  # python_etl:
  #   build:
  #     context: ./search_system/ETL_process
  #     dockerfile: Dockerfile_python
  #   container_name: etl_container
  #   volumes:
  #     - ./es_certs:/usr/certs
  #     - ./search_system/ETL_process/code:/app  # Persistent data storage for ETL
  #   depends_on:
  #     - elasticsearch
  #     - mysql_db
  #   profiles:
  #     - search    
  #   networks:
  #     - bigdata-net

# ----------------------------------
# AI Attribute Recommendation Service
# ----------------------------------
  pg_vector:
    image: ankane/pgvector:latest
    container_name: pg_vector_container
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: infopower
      POSTGRES_DB: vector_db
    ports:
      - "9100:5432"  # Expose PostgreSQL on port 9100
    volumes:
      - pg_data:/var/lib/postgresql/data  # Persistent data storage for PostgreSQL
    profiles:
      - ai_ml
    networks:
      - bigdata-net

  fastapi_seg_ai_service:
    build:
      context: ./ai_attribute_recommendation
      dockerfile: Dockerfile
    container_name: fastapi_seg_ai_service
    volumes:
      - ./ai_attribute_recommendation/app:/app
    ports:
      - "3003:3002" 
    depends_on:
      - pg_vector
    profiles:
      - ai_ml
    networks:
      - bigdata-net

  # --------------------
  # MinIO for object storage
  # --------------------
  minio:
    image: minio/minio
    container_name: minio
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio-data:/data
    environment:
      - MINIO_ROOT_USER=minioadmin
      - MINIO_ROOT_PASSWORD=minioadmin
    command: server /data --console-address ":9001"
    profiles: 
       - storage
    networks:
      - bigdata-net

  createbucket:
    image: minio/mc
    depends_on:
      - minio
    entrypoint: >
      /bin/sh -c "
        sleep 5;
        mc alias set local http://minio:9000 minioadmin minioadmin; 
        mc mb -p local/deltabucket;
        mc mb -p local/media-bucket;
        mc policy set public local/deltabucket;
        mc policy set public local/media-bucket;
        exit 0;
      "
    profiles:
      - storage
    networks:
      - bigdata-net

#   # --------------------
#   # Spark Cluster
#   # --------------------
  spark-master:
    build:
      context: ./spark_jobs
      dockerfile: Dockerfile
    container_name: spark-master
    volumes:
      - ./spark_volume:/home/jovyan/work
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=spark-master
      - PYSPARK_NO_DRIVER=true
      - PYSPARK_SUBMIT_ARGS=--jars /usr/local/spark/jars/delta-core_2.12-2.4.0.jar,/usr/local/spark/jars/delta-storage-2.4.0.jar pyspark-shell
    ports:
      - "7077:7077"
      - "8081:8080"
      - "4040:4040"
    profiles:
      - spark
    networks:
      - bigdata-net

  spark-worker-1:
    build:
      context: ./spark_jobs
      dockerfile: Dockerfile
    container_name: spark-worker-1
    volumes:
      - ./spark_volume:/home/jovyan/work
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=3G
      - SPARK_WORKER_CORES=2
      - SPARK_MASTER_HOST=spark-master
      - PYSPARK_NO_DRIVER=true
      - PYSPARK_SUBMIT_ARGS=--jars /usr/local/spark/jars/delta-core_2.12-2.4.0.jar,/usr/local/spark/jars/delta-storage-2.4.0.jar pyspark-shell
    profiles:
      - spark
    networks:
      - bigdata-net

  spark-worker-2:
    build:
      context: ./spark_jobs
      dockerfile: Dockerfile
    container_name: spark-worker-2
    volumes:
      - ./spark_volume:/home/jovyan/work
      - ./spark_jars/mysql-connector-j-8.0.33.jar:/opt/bitnami/spark/jars/mysql-connector-j-8.0.33.jar
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=3G
      - PYSPARK_NO_DRIVER=true
      - PYSPARK_SUBMIT_ARGS=--jars /usr/local/spark/jars/delta-core_2.12-2.4.0.jar,/usr/local/spark/jars/delta-storage-2.4.0.jar pyspark-shell
    profiles:
      - spark
    networks:
      - bigdata-net

  jupyter:
    build:
      context: ./spark_jobs
      dockerfile: Dockerfile_jupyter
    container_name: jupyter
    ports:
      - "8888:8888"
      - "4041:4040"
    volumes:
      - ./spark_volume:/home/jovyan/work
    environment:
      - PYSPARK_NO_DRIVER=true
      - PYSPARK_SUBMIT_ARGS=--jars /usr/local/spark/jars/delta-core_2.12-2.4.0.jar,/usr/local/spark/jars/delta-storage-2.4.0.jar pyspark-shell
      - JUPYTER_ENABLE_LAB=yes
    profiles:
      - spark
    command: jupyter lab --NotebookApp.token='' --NotebookApp.password=''
    depends_on:
      - spark-master
    networks:
      - bigdata-net

networks:
  bigdata-net:

volumes:
  minio-data:
  postgres_data:
  es_certs:
  pg_data:
  my-datavolume: