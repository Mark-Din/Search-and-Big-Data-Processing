{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22956d71",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'minio'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mminio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Minio\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'minio'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ---------- Config ----------\n",
    "MINIO_ENDPOINT = os.getenv(\"MINIO_ENDPOINT\", \"http://localhost:9000\")\n",
    "MINIO_ACCESS_KEY = os.getenv(\"MINIO_ACCESS_KEY\")\n",
    "MINIO_SECRET_KEY = os.getenv(\"MINIO_SECRET_KEY\")\n",
    "MINIO_BUCKET = os.getenv(\"MINIO_BUCKET\", \"deltabucket\")\n",
    "MINIO_PREFIX = os.getenv(\"MINIO_PREFIX\", \"\")  # e.g. 'gold/wholeCorp_delta'\n",
    "\n",
    "ES_URL = os.getenv(\"ES_URL\", \"http://localhost:9200\")\n",
    "ES_USERNAME = os.getenv(\"ES_USERNAME\")\n",
    "ES_PASSWORD = os.getenv(\"ES_PASSWORD\")\n",
    "ES_CA_CERT = os.getenv(\"ES_CA_CERT\")  # path or None\n",
    "ES_INDEX = os.getenv(\"ES_INDEX\", \"wholecorp\")\n",
    "\n",
    "CHUNKSIZE = int(os.getenv(\"CHUNKSIZE\", \"5000\"))  # rows per bulk batch\n",
    "\n",
    "# ---------- Clients ----------\n",
    "# s3fs uses the S3 API and works with MinIO\n",
    "fs = s3fs.S3FileSystem(\n",
    "    key=MINIO_ACCESS_KEY,\n",
    "    secret=MINIO_SECRET_KEY,\n",
    "    client_kwargs={\"endpoint_url\": MINIO_ENDPOINT},\n",
    ")\n",
    "\n",
    "# Elasticsearch client\n",
    "es_kwargs = {\"basic_auth\": (ES_USERNAME, ES_PASSWORD)} if ES_USERNAME else {}\n",
    "if ES_URL.startswith(\"https\"):\n",
    "    es_kwargs[\"verify_certs\"] = True if ES_CA_CERT else False\n",
    "    if ES_CA_CERT:\n",
    "        es_kwargs[\"ca_certs\"] = ES_CA_CERT\n",
    "\n",
    "es = Elasticsearch(ES_URL, **es_kwargs)\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def ensure_index(es: Elasticsearch, index: str):\n",
    "    \"\"\"Create the index with a simple mapping if it doesn't exist.\"\"\"\n",
    "    if es.indices.exists(index=index):\n",
    "        return\n",
    "    body = {\n",
    "        \"settings\": {\n",
    "            \"number_of_shards\": 1,\n",
    "            \"number_of_replicas\": 0\n",
    "        },\n",
    "        \"mappings\": {\n",
    "            \"dynamic\": True,\n",
    "            \"date_detection\": True,\n",
    "            \"dynamic_templates\": [\n",
    "                # treat *_at or *_date as dates when possible\n",
    "                {\"dates\": {\"match_pattern\": \"regex\", \"match\": \".*(_at|_date|Date|timestamp)$\",\n",
    "                           \"mapping\": {\"type\": \"date\", \"ignore_malformed\": True}}},\n",
    "                # numeric strings -> try as keywords by default (let dynamic handle numerics)\n",
    "            ],\n",
    "        }\n",
    "    }\n",
    "    es.indices.create(index=index, body=body)\n",
    "\n",
    "def _stable_id(doc: Dict[str, Any]) -> str:\n",
    "    \"\"\"Create a stable _id to deduplicate. Customize to your schema.\"\"\"\n",
    "    raw = json.dumps(doc, sort_keys=True, ensure_ascii=False)\n",
    "    return hashlib.md5(raw.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "def dict_rows_from_csv(s3_path: str, chunksize: int) -> Iterator[Dict[str, Any]]:\n",
    "    with fs.open(s3_path, \"rb\") as f:\n",
    "        for chunk in pd.read_csv(f, chunksize=chunksize):\n",
    "            # (Optional) normalize/clean here\n",
    "            # e.g., convert 'updatedAt' to ISO\n",
    "            if \"updatedAt\" in chunk.columns:\n",
    "                chunk[\"updatedAt\"] = pd.to_datetime(chunk[\"updatedAt\"], errors=\"coerce\").dt.tz_localize(None)\n",
    "            for record in chunk.to_dict(orient=\"records\"):\n",
    "                yield record\n",
    "\n",
    "def dict_rows_from_jsonl(s3_path: str) -> Iterator[Dict[str, Any]]:\n",
    "    with fs.open(s3_path, \"rb\") as f:\n",
    "        for line in f:\n",
    "            if not line:\n",
    "                continue\n",
    "            rec = json.loads(line.decode(\"utf-8\"))\n",
    "            yield rec\n",
    "\n",
    "def dict_rows_from_parquet(s3_path: str, chunksize: int) -> Iterator[Dict[str, Any]]:\n",
    "    # Parquet isn't naturally chunked; load in frames then split (memory ok for moderate size).\n",
    "    # For huge data, consider PyArrow row groups iteration.\n",
    "    df = pd.read_parquet(f\"s3://{s3_path}\", storage_options={\n",
    "        \"key\": MINIO_ACCESS_KEY,\n",
    "        \"secret\": MINIO_SECRET_KEY,\n",
    "        \"client_kwargs\": {\"endpoint_url\": MINIO_ENDPOINT},\n",
    "    })\n",
    "    if \"updatedAt\" in df.columns:\n",
    "        df[\"updatedAt\"] = pd.to_datetime(df[\"updatedAt\"], errors=\"coerce\").dt.tz_localize(None)\n",
    "    if len(df) <= chunksize:\n",
    "        for r in df.to_dict(orient=\"records\"):\n",
    "            yield r\n",
    "    else:\n",
    "        for start in range(0, len(df), chunksize):\n",
    "            sub = df.iloc[start:start+chunksize]\n",
    "            for r in sub.to_dict(orient=\"records\"):\n",
    "                yield r\n",
    "\n",
    "def actions_from_docs(docs: Iterable[Dict[str, Any]], index: str) -> Iterator[Dict[str, Any]]:\n",
    "    for d in docs:\n",
    "        # (Optional) field remaps / type fixes\n",
    "        # Example: coerce numeric strings\n",
    "        # for k in (\"amount\",\"price\",\"count\"):\n",
    "        #     if k in d:\n",
    "        #         try: d[k] = float(d[k])\n",
    "        #         except: pass\n",
    "\n",
    "        yield {\n",
    "            \"_op_type\": \"index\",\n",
    "            \"_index\": index,\n",
    "            \"_id\": d.get(\"_id\") or _stable_id(d),\n",
    "            \"_source\": d,\n",
    "        }\n",
    "\n",
    "def s3_keys(bucket: str, prefix: str = \"\") -> Iterator[str]:\n",
    "    path = f\"{bucket}/{prefix}\".rstrip(\"/\")\n",
    "    for key in fs.find(path):\n",
    "        # fs.find returns full paths like 'bucket/key'\n",
    "        yield key\n",
    "\n",
    "# ---------- Main pump ----------\n",
    "def pump_object(key: str, index: str):\n",
    "    s3_path = key  # already like 'bucket/key.ext'\n",
    "    lower = s3_path.lower()\n",
    "    if lower.endswith(\".csv\"):\n",
    "        docs = dict_rows_from_csv(s3_path, chunksize=CHUNKSIZE)\n",
    "    elif lower.endswith(\".jsonl\") or lower.endswith(\".ndjson\"):\n",
    "        docs = dict_rows_from_jsonl(s3_path)\n",
    "    elif lower.endswith(\".parquet\"):\n",
    "        docs = dict_rows_from_parquet(s3_path, chunksize=CHUNKSIZE)\n",
    "    else:\n",
    "        print(f\"Skip unsupported file type: {s3_path}\")\n",
    "        return\n",
    "\n",
    "    # Stream to ES\n",
    "    success, fail = 0, 0\n",
    "    for ok, resp in streaming_bulk(es, actions_from_docs(docs, index=index), chunk_size=CHUNKSIZE, max_retries=3):\n",
    "        if ok:\n",
    "            success += 1\n",
    "        else:\n",
    "            fail += 1\n",
    "    print(f\"[{s3_path}] bulk result: success={success}, failed={fail}\")\n",
    "\n",
    "def main():\n",
    "    ensure_index(es, ES_INDEX)\n",
    "    root = f\"{MINIO_BUCKET}/{MINIO_PREFIX}\" if MINIO_PREFIX else MINIO_BUCKET\n",
    "    keys = list(s3_keys(MINIO_BUCKET, MINIO_PREFIX))\n",
    "    if not keys:\n",
    "        print(f\"No objects found under s3://{root}\")\n",
    "        return\n",
    "    for key in keys:\n",
    "        pump_object(key, ES_INDEX)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6c46471c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs, pyarrow.parquet as pq, pandas as pd\n",
    "\n",
    "fs = s3fs.S3FileSystem(\n",
    "    key=\"minioadmin\", secret=\"minioadmin\",\n",
    "    client_kwargs={\"endpoint_url\": \"http://localhost:9000\"}\n",
    ")\n",
    "\n",
    "prefix = \"deltabucket/silver/wholeCorp_delta\"\n",
    "files = fs.glob(f\"{prefix}/*.parquet\")\n",
    "\n",
    "dfs = []\n",
    "for f in files:\n",
    "    table = pq.ParquetDataset(f\"s3://{f}\", filesystem=fs).read()\n",
    "    df = table.to_pandas()\n",
    "    dfs.append(df)\n",
    "\n",
    "df_whole_silver = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "prefix = \"deltabucket/gold/wholeCorp_delta\"\n",
    "files = fs.glob(f\"{prefix}/*.parquet\")\n",
    "\n",
    "dfs = []\n",
    "for f in files:\n",
    "    table = pq.ParquetDataset(f\"s3://{f}\", filesystem=fs).read()\n",
    "    df = table.to_pandas()\n",
    "    dfs.append(df)\n",
    "\n",
    "df_whole_gold = pd.concat(dfs)\n",
    "\n",
    "df_merged = df_whole_silver.merge(df_whole_gold[['統一編號','features']], on= \"統一編號\", how='left')\n",
    "df_merged = df_merged[['統一編號', '公司名稱', '負責人', '登記地址', '資本額', '營業項目及代碼表', '縣市名稱', '區域名稱',\n",
    "        '類別_全', '官網', '電話', 'features']]\n",
    "df_merged.rename(columns={'features':'features_vector'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "91696bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 0,\n",
       " 'size': 262147,\n",
       " 'indices': array([178355, 262144, 262145, 262146], dtype=int32),\n",
       " 'values': array([5.21230542, 2.32432391, 0.        , 0.        ])}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.features_vector[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fd0dc4a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 13\u001b[0m\n\u001b[0;32m      9\u001b[0m     dense[indices] \u001b[38;5;241m=\u001b[39m values\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dense\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m---> 13\u001b[0m df_merged[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures_vector\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_merged\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfeatures_vector\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_dense\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_merged[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m公司名稱\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures_vector\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\nexva_penta_integration_env\\lib\\site-packages\\pandas\\core\\series.py:4935\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4800\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4801\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4802\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4807\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4808\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4809\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4810\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4811\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4926\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4927\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4928\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4930\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4931\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4932\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4933\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4934\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4935\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\nexva_penta_integration_env\\lib\\site-packages\\pandas\\core\\apply.py:1422\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1421\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1422\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\nexva_penta_integration_env\\lib\\site-packages\\pandas\\core\\apply.py:1502\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1500\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1502\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1503\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1504\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1507\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1508\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\nexva_penta_integration_env\\lib\\site-packages\\pandas\\core\\base.py:925\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    923\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 925\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\nexva_penta_integration_env\\lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mpandas/_libs/lib.pyx:2999\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[57], line 10\u001b[0m, in \u001b[0;36mto_dense\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m      8\u001b[0m dense \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(size, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m)\n\u001b[0;32m      9\u001b[0m dense[indices] \u001b[38;5;241m=\u001b[39m values\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdense\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# convert \"features\" struct into dense numpy vector\n",
    "def to_dense(row):\n",
    "    if pd.isna(row):\n",
    "        return None\n",
    "    indices = row[\"indices\"]\n",
    "    values = row[\"values\"]\n",
    "    size = row[\"size\"]\n",
    "    dense = np.zeros(size, dtype=float)\n",
    "    dense[indices] = values\n",
    "    return dense.tolist()\n",
    "\n",
    "\n",
    "df_merged[\"features_vector\"] = df_merged[\"features_vector\"].apply(to_dense)\n",
    "print(df_merged[[\"公司名稱\",\"features_vector\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22839118",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52394493",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'elasticsearch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Iterator, Dict, Any, Iterable\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01melasticsearch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Elasticsearch\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01melasticsearch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhelpers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m streaming_bulk\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01ms3fs\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'elasticsearch'"
     ]
    }
   ],
   "source": [
    "# --- Read Delta from MinIO ---\n",
    "storage_options = {\n",
    "    \"AWS_ACCESS_KEY_ID\": \"minioadmin\",\n",
    "    \"AWS_SECRET_ACCESS_KEY\": \"minioadmin\",\n",
    "    \"AWS_ENDPOINT_URL\": MINIO_ENDPOINT,\n",
    "}\n",
    "\n",
    "dt = DeltaTable(DELTA_PATH, storage_options=storage_options)\n",
    "\n",
    "# Convert to Pandas (you can chunk if too big)\n",
    "df = dt.to_pandas()\n",
    "\n",
    "# --- Send to Elasticsearch ---\n",
    "es = Elasticsearch(ES_URL)\n",
    "\n",
    "def docs():\n",
    "    for rec in df.to_dict(orient=\"records\"):\n",
    "        yield {\"_index\": ES_INDEX, \"_source\": rec}\n",
    "\n",
    "helpers.bulk(es, docs())\n",
    "print(f\"Inserted {len(df)} records into {ES_INDEX}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1f0677",
   "metadata": {},
   "outputs": [],
   "source": [
    "import s3fs, json\n",
    "\n",
    "fs = s3fs.S3FileSystem(\n",
    "    key=\"minioadmin\",\n",
    "    secret=\"minioadmin\",\n",
    "    client_kwargs={\"endpoint_url\": \"http://localhost:9000\"},\n",
    ")\n",
    "\n",
    "log_path = \"deltabucket/gold/wholeCorp_delta/_delta_log/00000000000000000000.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459d50b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"commitInfo\":{\"timestamp\":1756348865596,\"operation\":\"WRITE\",\"operationParameters\":{\"mode\":\"Overwrite\",\"partitionBy\":\"[]\"},\"isolationLevel\":\"Serializable\",\"isBlindAppend\":false,\"operationMetrics\":{\"numFiles\":\"3\",\"numOutputRows\":\"1379786\",\"numOutputBytes\":\"50111755\"},\"engineInfo\":\"Apache-Spark/3.5.0 Delta-Lake/3.1.0\",\"txnId\":\"c5fc9746-d3b9-4f5e-bf3a-b0c9fd0da940\"}}\\n'\n",
      "b'{\"metaData\":{\"id\":\"39abccd6-8638-43ab-a593-82213368be39\",\"format\":{\"provider\":\"parquet\",\"options\":{}},\"schemaString\":\"{\\\\\"type\\\\\":\\\\\"struct\\\\\",\\\\\"fields\\\\\":[{\\\\\"name\\\\\":\\\\\"\\xe7\\xb5\\xb1\\xe4\\xb8\\x80\\xe7\\xb7\\xa8\\xe8\\x99\\x9f\\\\\",\\\\\"type\\\\\":\\\\\"string\\\\\",\\\\\"nullable\\\\\":true,\\\\\"metadata\\\\\":{}},{\\\\\"name\\\\\":\\\\\"\\xe5\\x85\\xac\\xe5\\x8f\\xb8\\xe5\\x90\\x8d\\xe7\\xa8\\xb1\\\\\",\\\\\"type\\\\\":\\\\\"string\\\\\",\\\\\"nullable\\\\\":true,\\\\\"metadata\\\\\":{}},{\\\\\"name\\\\\":\\\\\"features\\\\\",\\\\\"type\\\\\":{\\\\\"type\\\\\":\\\\\"udt\\\\\",\\\\\"class\\\\\":\\\\\"org.apache.spark.ml.linalg.VectorUDT\\\\\",\\\\\"pyClass\\\\\":\\\\\"pyspark.ml.linalg.VectorUDT\\\\\",\\\\\"sqlType\\\\\":{\\\\\"type\\\\\":\\\\\"struct\\\\\",\\\\\"fields\\\\\":[{\\\\\"name\\\\\":\\\\\"type\\\\\",\\\\\"type\\\\\":\\\\\"byte\\\\\",\\\\\"nullable\\\\\":false,\\\\\"metadata\\\\\":{}},{\\\\\"name\\\\\":\\\\\"size\\\\\",\\\\\"type\\\\\":\\\\\"integer\\\\\",\\\\\"nullable\\\\\":true,\\\\\"metadata\\\\\":{}},{\\\\\"name\\\\\":\\\\\"indices\\\\\",\\\\\"type\\\\\":{\\\\\"type\\\\\":\\\\\"array\\\\\",\\\\\"elementType\\\\\":\\\\\"integer\\\\\",\\\\\"containsNull\\\\\":false},\\\\\"nullable\\\\\":true,\\\\\"metadata\\\\\":{}},{\\\\\"name\\\\\":\\\\\"values\\\\\",\\\\\"type\\\\\":{\\\\\"type\\\\\":\\\\\"array\\\\\",\\\\\"elementType\\\\\":\\\\\"double\\\\\",\\\\\"containsNull\\\\\":false},\\\\\"nullable\\\\\":true,\\\\\"metadata\\\\\":{}}]}},\\\\\"nullable\\\\\":true,\\\\\"metadata\\\\\":{\\\\\"ml_attr\\\\\":{\\\\\"num_attrs\\\\\":262147}}}]}\",\"partitionColumns\":[],\"configuration\":{},\"createdTime\":1756348848596}}\\n'\n",
      "b'{\"protocol\":{\"minReaderVersion\":1,\"minWriterVersion\":2}}\\n'\n",
      "b'{\"add\":{\"path\":\"part-00001-28553252-2ce9-4096-b0c0-56f743c61e24-c000.snappy.parquet\",\"partitionValues\":{},\"size\":31911264,\"modificationTime\":1756348865000,\"dataChange\":true,\"stats\":\"{\\\\\"numRecords\\\\\":853932,\\\\\"minValues\\\\\":{\\\\\"\\xe7\\xb5\\xb1\\xe4\\xb8\\x80\\xe7\\xb7\\xa8\\xe8\\x99\\x9f\\\\\":\\\\\"00000228\\\\\",\\\\\"\\xe5\\x85\\xac\\xe5\\x8f\\xb8\\xe5\\x90\\x8d\\xe7\\xa8\\xb1\\\\\":\\\\\",\\xe6\\xb8\\x85\\xe9\\xa0\\x86\\xe8\\x88\\x88\\xe5\\x95\\x86\\xe8\\x99\\x9f\\\\\"},\\\\\"maxValues\\\\\":{\\\\\"\\xe7\\xb5\\xb1\\xe4\\xb8\\x80\\xe7\\xb7\\xa8\\xe8\\x99\\x9f\\\\\":\\\\\"Z5905069\\\\\",\\\\\"\\xe5\\x85\\xac\\xe5\\x8f\\xb8\\xe5\\x90\\x8d\\xe7\\xa8\\xb1\\\\\":\\\\\"\\xf0\\xa8\\xa9\\x86\\xe9\\x8b\\x90\\xe9\\x87\\x91\\xe5\\xb1\\xac\\xe5\\xb7\\xa5\\xe7\\xa8\\x8b\\xe8\\xa1\\x8c\\\\\"},\\\\\"nullCount\\\\\":{\\\\\"\\xe7\\xb5\\xb1\\xe4\\xb8\\x80\\xe7\\xb7\\xa8\\xe8\\x99\\x9f\\\\\":0,\\\\\"\\xe5\\x85\\xac\\xe5\\x8f\\xb8\\xe5\\x90\\x8d\\xe7\\xa8\\xb1\\\\\":0,\\\\\"features\\\\\":0}}\"}}\\n'\n",
      "b'{\"add\":{\"path\":\"part-00002-511bc212-93c5-45cc-af32-e9a0515f3ee7-c000.snappy.parquet\",\"partitionValues\":{},\"size\":18199335,\"modificationTime\":1756348860000,\"dataChange\":true,\"stats\":\"{\\\\\"numRecords\\\\\":525854,\\\\\"minValues\\\\\":{\\\\\"\\xe7\\xb5\\xb1\\xe4\\xb8\\x80\\xe7\\xb7\\xa8\\xe8\\x99\\x9f\\\\\":\\\\\"00000001\\\\\",\\\\\"\\xe5\\x85\\xac\\xe5\\x8f\\xb8\\xe5\\x90\\x8d\\xe7\\xa8\\xb1\\\\\":\\\\\"!<\\xe6\\x88\\x91\\xe7\\x9c\\x8b\\xe7\\x9a\\x84\\xe5\\x88\\xb0\\xe4\\xbd\\xa0>3G\\xe8\\xa1\\x8c\\xe5\\x8b\\x95\\xe4\\xbf\\x9d\\xe5\\x85\\xa8\\xe5\\xae\\x88\\xe8\\xad\\xb7\\xe7\\xa5\\x9e\\xe7\\xb3\\xbb\\xe7\\xb5\\xb1\\\\\"},\\\\\"maxValues\\\\\":{\\\\\"\\xe7\\xb5\\xb1\\xe4\\xb8\\x80\\xe7\\xb7\\xa8\\xe8\\x99\\x9f\\\\\":\\\\\"y2205321\\\\\",\\\\\"\\xe5\\x85\\xac\\xe5\\x8f\\xb8\\xe5\\x90\\x8d\\xe7\\xa8\\xb1\\\\\":\\\\\"\\xf0\\xa7\\x99\\x97\\xe7\\x9b\\x9b\\xe8\\x94\\xac\\xe8\\x8f\\x9c\\xe8\\xa1\\x8c\\\\\"},\\\\\"nullCount\\\\\":{\\\\\"\\xe7\\xb5\\xb1\\xe4\\xb8\\x80\\xe7\\xb7\\xa8\\xe8\\x99\\x9f\\\\\":0,\\\\\"\\xe5\\x85\\xac\\xe5\\x8f\\xb8\\xe5\\x90\\x8d\\xe7\\xa8\\xb1\\\\\":0,\\\\\"features\\\\\":0}}\"}}\\n'\n"
     ]
    }
   ],
   "source": [
    "with fs.open(log_path) as f:\n",
    "    for line in f:\n",
    "        print(line)\n",
    "        obj = json.loads(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3249cd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema string:\n",
      "{\"type\":\"struct\",\"fields\":[{\"name\":\"統一編號\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"公司名稱\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"features\",\"type\":{\"type\":\"udt\",\"class\":\"org.apache.spark.ml.linalg.VectorUDT\",\"pyClass\":\"pyspark.ml.linalg.VectorUDT\",\"sqlType\":{\"type\":\"struct\",\"fields\":[{\"name\":\"type\",\"type\":\"byte\",\"nullable\":false,\"metadata\":{}},{\"name\":\"size\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"indices\",\"type\":{\"type\":\"array\",\"elementType\":\"integer\",\"containsNull\":false},\"nullable\":true,\"metadata\":{}},{\"name\":\"values\",\"type\":{\"type\":\"array\",\"elementType\":\"double\",\"containsNull\":false},\"nullable\":true,\"metadata\":{}}]}},\"nullable\":true,\"metadata\":{\"ml_attr\":{\"num_attrs\":262147}}}]}\n"
     ]
    }
   ],
   "source": [
    "with fs.open(log_path) as f:\n",
    "    for line in f:\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        obj = json.loads(line)\n",
    "        if \"metaData\" in obj:\n",
    "            print(\"Schema string:\")\n",
    "            print(obj[\"metaData\"][\"schemaString\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nexva_penta_integration_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
