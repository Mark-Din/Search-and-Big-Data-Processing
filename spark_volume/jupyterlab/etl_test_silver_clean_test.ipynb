{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92260340-8b12-4c9b-bcbe-e803bd6f331a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from pyspark.sql import SparkSession, functions as F, types as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11e99095-32cb-460a-bf67-9c119c04cd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "def spark_session():\n",
    "    # Stop any old session so new configs take effect in notebooks\n",
    "    return (\n",
    "        SparkSession.builder\n",
    "        .appName(\"MySQL_to_Delta_on_MinIO\")\n",
    "        .master(\"spark://spark-master:7077\")\n",
    "        .config(\"spark.jars.packages\",\n",
    "                \",\".join([\n",
    "                    # Delta\n",
    "                    \"io.delta:delta-spark_2.12:3.1.0\",\n",
    "                    # MySQL JDBC\n",
    "                    \"mysql:mysql-connector-java:8.0.33\",\n",
    "                    # S3A / MinIO (versions must match your Hadoop)\n",
    "                    \"org.apache.hadoop:hadoop-aws:3.3.2\",\n",
    "                    \"com.amazonaws:aws-java-sdk-bundle:1.11.1026\",\n",
    "                ]))\n",
    "        # Delta integration\n",
    "        .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "        .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "        # MinIO (S3A) configs\n",
    "        .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\")\n",
    "        .config(\"spark.hadoop.fs.s3a.access.key\", \"minioadmin\")\n",
    "        .config(\"spark.hadoop.fs.s3a.secret.key\", \"minioadmin\")\n",
    "        .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\n",
    "        .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "        .config(\"spark.hadoop.fs.s3a.connection.ssl.enabled\", \"false\")\n",
    "        .config(\"spark.ui.port\", \"4040\")                 # fix the port\n",
    "        .config(\"spark.driver.bindAddress\", \"0.0.0.0\")   # listen on all ifaces\n",
    "        .config(\"spark.driver.host\", \"jupyter\")          # OR \"spark-master\" – the container's DNS name\n",
    "        .config(\"spark.ui.showConsoleProgress\", \"true\")\n",
    "        # Resources\n",
    "        # .config(\"spark.executor.cores\", \"2\")\n",
    "        # .config(\"spark.executor.memory\", \"2g\")\n",
    "        # .config(\"spark.executor.memoryOverhead\", \"1536m\")\n",
    "        # .config(\"spark.network.timeout\", \"600s\")\n",
    "        .config(\"spark.executor.cores\", \"1\")           # 1 task per executor (more stable for trees)\n",
    "        .config(\"spark.executor.memory\", \"3g\")\n",
    "        .config(\"spark.executor.memoryOverhead\", \"1g\")  # or omit in Standalone\n",
    "        .config(\"spark.sql.shuffle.partitions\", \"50\")\n",
    "        # .config(\"spark.local.dir\", \"/mnt/spark-tmp/local\") # For giving it much more space to run CV\n",
    "        .config(\"spark.network.timeout\", \"600s\")\n",
    "        .getOrCreate()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "940fc0c1-fee0-4fe7-9973-8d297b2085e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_mysql(spark):\n",
    "    # 2) Read MySQL\n",
    "    return (spark.read.format(\"jdbc\")\n",
    "      .option(\"url\", \"jdbc:mysql://mysql_db_container:3306/whole_corp\"\n",
    "                      \"?useUnicode=true&characterEncoding=utf8\"\n",
    "                      \"&serverTimezone=Asia/Taipei\"\n",
    "                      \"&useSSL=false&allowPublicKeyRetrieval=true\")\n",
    "      .option(\"dbtable\", \"whole_corp\")\n",
    "      .option(\"user\", \"root\")\n",
    "      .option(\"password\", \"!QAZ2wsx\")\n",
    "      .option(\"driver\", \"com.mysql.cj.jdbc.Driver\")\n",
    "      .load())\n",
    "\n",
    "\n",
    "def bronze_to_silver(s):\n",
    "    # Read Bronze (from MinIO or local)\n",
    "    bronze_path = os.getenv(\"BRONZE_PATH\", \"s3a://deltabucket/bronze/wholeCorp_delta_raw\")\n",
    "    df = s.read.parquet(bronze_path)\n",
    "\n",
    "    # Coerce types\n",
    "    to_int = [\"資本額\",\"實收資本總額\",\"員工\"]\n",
    "    for c in to_int:\n",
    "        if c in df.columns:\n",
    "            df = df.withColumn(c, F.regexp_replace(F.col(c), r\"[^\\d]\", \"\").cast(\"long\"))\n",
    "\n",
    "    if \"成立年份\" in df.columns:\n",
    "        df = df.withColumn(\"公司年齡\", F.lit(F.year(F.current_date())) - F.col(\"成立年份\").cast(\"int\"))\n",
    "\n",
    "    # Trim strings\n",
    "    for c, t in df.dtypes:\n",
    "        if t == \"string\":\n",
    "            df = df.withColumn(c, F.trim(F.col(c)))\n",
    "            \n",
    "    # Drop rows with nulls in critical columns\n",
    "    critical_cols = [\"公司名稱\", \"統一編號\"]\n",
    "    df = df.dropna(subset=critical_cols)\n",
    "\n",
    "    df = df.filter(~df['統一編號'].rlike('.*[A-Za-z].*'))\n",
    "    \n",
    "    silver_path = os.getenv(\"SILVER_PATH\", \"s3a://deltabucket/silver/wholeCorp_delta\")\n",
    "    df.write.format(\"delta\").mode(\"overwrite\").save(silver_path)\n",
    "\n",
    "\n",
    "def store_in_minio(df):\n",
    "    # 3) Write Delta to MinIO\n",
    "    (df.write.format(\"delta\")\n",
    "       .mode(\"overwrite\")\n",
    "       .save(\"s3a://deltabucket/bronze/wholeCorp_delta_raw\"))\n",
    "\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        s = spark_session()\n",
    "        df = read_from_mysql(s)\n",
    "        store_in_minio(df)\n",
    "        bronze_to_silver(s)\n",
    "        s.stop()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        try:\n",
    "            s.stop()\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19ad3ee-d24f-4ce4-9379-0f6fc0963533",
   "metadata": {},
   "source": [
    "# Read the files minio version by using delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c55a5ee3-a452-4e3d-a815-8270c4be15ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from delta.tables import DeltaTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffd39c65-5514-494e-9dce-13846e64064b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = spark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8e5b011-3820-4b0b-9b57-2fd598bd007e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[version: bigint, timestamp: timestamp, userId: string, userName: string, operation: string, operationParameters: map<string,string>, job: struct<jobId:string,jobName:string,jobRunId:string,runId:string,jobOwnerId:string,triggerType:string>, notebook: struct<notebookId:string>, clusterId: string, readVersion: bigint, isolationLevel: string, isBlindAppend: boolean, operationMetrics: map<string,string>, userMetadata: string, engineInfo: string]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_path = \"s3a://deltabucket/bronze/wholeCorp_delta_raw\"\n",
    "\n",
    "dt = DeltaTable.forPath(s, delta_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee388e04-8b0f-4cb6-995d-8a24f6bf6225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History of changes:\n",
      "+-------+-------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+----------------------------------------------------------------------+------------+-----------------------------------+\n",
      "|version|timestamp          |userId|userName|operation|operationParameters                   |job |notebook|clusterId|readVersion|isolationLevel|isBlindAppend|operationMetrics                                                      |userMetadata|engineInfo                         |\n",
      "+-------+-------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+----------------------------------------------------------------------+------------+-----------------------------------+\n",
      "|1      |2025-09-11 01:46:33|NULL  |NULL    |WRITE    |{mode -> Overwrite, partitionBy -> []}|NULL|NULL    |NULL     |0          |Serializable  |false        |{numFiles -> 1, numOutputRows -> 1379786, numOutputBytes -> 182476763}|NULL        |Apache-Spark/3.5.0 Delta-Lake/3.1.0|\n",
      "|0      |2025-08-28 02:34:04|NULL  |NULL    |WRITE    |{mode -> Overwrite, partitionBy -> []}|NULL|NULL    |NULL     |NULL       |Serializable  |false        |{numFiles -> 1, numOutputRows -> 1379786, numOutputBytes -> 182476763}|NULL        |Apache-Spark/3.5.0 Delta-Lake/3.1.0|\n",
      "+-------+-------------------+------+--------+---------+--------------------------------------+----+--------+---------+-----------+--------------+-------------+----------------------------------------------------------------------+------------+-----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show current data files\n",
    "active_files = dt.history()  # shows commit history\n",
    "print(\"History of changes:\")\n",
    "active_files.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcb902c-df61-4e46-b753-56ab93461d6c",
   "metadata": {},
   "source": [
    "# Extract from mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3670ca20-1a84-42dc-baa8-10ef20a44b16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# s.read.format(\"jdbc\") \\\n",
    "#  .option(\"url\",\"jdbc:mysql://root:!QAZ2wsx@mysql-business-only:3306\") \\\n",
    "#  .option(\"dbtable\",\"(SELECT 1) AS t\") \\\n",
    "#  .option(\"user\",\"user\").option(\"password\",\"!QAZ2wsx\") \\\n",
    "#  .option(\"driver\",\"com.mysql.cj.jdbc.Driver\") \\\n",
    "#  .load().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a7e5012-73ce-49c1-8d41-42ed37fdc5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (s.read.format(\"jdbc\")\n",
    "      .option(\"url\", \"jdbc:mysql://root:!QAZ2wsx@mysql-business-only:3306/whole_corp\"\n",
    "                      \"?useUnicode=true&characterEncoding=utf8\"\n",
    "                      \"&serverTimezone=Asia/Taipei\"\n",
    "                      \"&useSSL=false&allowPublicKeyRetrieval=true\")\n",
    "      .option(\"dbtable\", \"whole_corp\")  # or \"schema.table\" if needed\n",
    "      .option(\"user\", \"user\")\n",
    "      .option(\"password\", \"!QAZ2wsx\")\n",
    "      .option(\"driver\", \"com.mysql.cj.jdbc.Driver\")\n",
    "      .load())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
